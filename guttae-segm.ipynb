{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Corneal Endothelial Cell (CEC) Image Segmentation with U-Net Architecture","metadata":{}},{"cell_type":"code","source":"!pip install imutils","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:27:38.266567Z","iopub.execute_input":"2022-06-16T03:27:38.267001Z","iopub.status.idle":"2022-06-16T03:27:51.630852Z","shell.execute_reply.started":"2022-06-16T03:27:38.266918Z","shell.execute_reply":"2022-06-16T03:27:51.629546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport os, cv2, random, imutils, re\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow.keras.layers import Dropout, Input, Dense, UpSampling2D, concatenate, Add, MaxPooling2D\nfrom tensorflow.keras.layers import Layer, Dense, Flatten, Conv2D, Conv2DTranspose, Dropout\nfrom tensorflow.keras.layers import add, BatchNormalization, ReLU, Activation, LeakyReLU\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow_addons as tfa\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:27:51.633929Z","iopub.execute_input":"2022-06-16T03:27:51.635428Z","iopub.status.idle":"2022-06-16T03:27:57.720435Z","shell.execute_reply.started":"2022-06-16T03:27:51.63536Z","shell.execute_reply":"2022-06-16T03:27:57.719318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def number(filename): \n    if 'cor' in filename: return int(filename[4:-4])\n    elif 'cell' in filename: return int(filename[5:-4])\n    elif 'guttae' in filename: return int(filename[7:-4])\n    else: print('Error was found.') # if the label is missing.\n        \ndef read_cec_patches(folder): # read images sequentially.\n    images = []; names = [] # vectors to store the outputs.\n    orderly_list = sorted(os.listdir(folder), key = number)\n    for filename in orderly_list: # review each image as read, input.\n        img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_GRAYSCALE)\n        if img is not None: # if the image is not empty, proceed.\n            images.append(img); names.append(filename)\n    return images, names # returned vectors.","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:27:57.721983Z","iopub.execute_input":"2022-06-16T03:27:57.722681Z","iopub.status.idle":"2022-06-16T03:27:57.732822Z","shell.execute_reply.started":"2022-06-16T03:27:57.72264Z","shell.execute_reply":"2022-06-16T03:27:57.731133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_synth = '../input/patches-bd/backup-synth'\nimages, fn_cor = read_cec_patches(path_synth + '/images')\ncells, fn_cell = read_cec_patches(path_synth + '/masks/cells')\nguttaes, fn_guttae = read_cec_patches(path_synth + '/masks/guttae')\nimages = np.array(images); images = np.expand_dims(images, axis = -1)\ncells = np.array(cells); cells = np.expand_dims(cells, axis = -1) \nguttaes = np.array(guttaes); guttaes = np.expand_dims(guttaes, axis = -1)\nbackgrounds = cells + guttaes; backgrounds = 1 - backgrounds # contours.\nmasks = np.concatenate((backgrounds, cells, guttaes), axis = -1)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:28:51.08035Z","iopub.execute_input":"2022-06-16T03:28:51.081156Z","iopub.status.idle":"2022-06-16T03:30:13.918761Z","shell.execute_reply.started":"2022-06-16T03:28:51.081119Z","shell.execute_reply":"2022-06-16T03:30:13.917763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('CEC Images :::', images.shape); print('CEC Masks :::', masks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:31:17.37368Z","iopub.execute_input":"2022-06-16T03:31:17.374206Z","iopub.status.idle":"2022-06-16T03:31:17.379197Z","shell.execute_reply.started":"2022-06-16T03:31:17.374163Z","shell.execute_reply":"2022-06-16T03:31:17.378341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encoder_pixels(msk):\n    labels = []\n    cll = np.expand_dims(msk[..., 1], axis = 3)\n    gtt = np.expand_dims(msk[..., 2], axis = 3)\n    for n in range(len(msk)):\n        c = cll[n] / 255\n        g = gtt[n] / 255\n        g[g == 1] = 2\n        new_m = c + g\n        labels.append(new_m)\n    return np.asarray(labels)\n\nlabels = encoder_pixels(masks)\nprint('CEC Masks :::', labels.shape)\nprint('Pixels Class ::: ', np.unique(labels))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_patches(artifact_list):\n    plt.figure(figsize = (15, 15))\n    graph = tf.keras.preprocessing.image.array_to_img\n    title = ['CEC Image','Contour Mask','Cell Mask','Guttae Mask','Unified Mask']\n    for x in range(len(artifact_list)):    \n        plt.subplot(1,len(artifact_list),x+1); plt.title(title[x])\n        plt.imshow(graph(artifact_list[x])); plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T06:30:04.566901Z","iopub.execute_input":"2022-06-16T06:30:04.567324Z","iopub.status.idle":"2022-06-16T06:30:04.577792Z","shell.execute_reply.started":"2022-06-16T06:30:04.56727Z","shell.execute_reply":"2022-06-16T06:30:04.577037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"e = random.sample(range(0, len(images)), 1)\ncec_image = np.squeeze(images[e], axis = 0)\ncec_mask = np.squeeze(masks[e], axis = 0)\ncontour = np.expand_dims(cec_mask[..., 0], axis = 2)\ncell = np.expand_dims(cec_mask[..., 1], axis = 2)\nguttae = np.expand_dims(cec_mask[..., 2], axis = 2)\ndisplay_patches([cec_image,contour,cell,guttae,labels[e[0]]])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T06:30:14.032958Z","iopub.execute_input":"2022-06-16T06:30:14.033377Z","iopub.status.idle":"2022-06-16T06:30:14.333248Z","shell.execute_reply.started":"2022-06-16T06:30:14.03334Z","shell.execute_reply":"2022-06-16T06:30:14.332199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def counter_guttaes(guttae):\n    c_guttae = []; rating = []; type_p = []\n    for n in range(len(guttae)):\n        cnts = cv2.findContours(guttae[n].copy(), cv2.RETR_EXTERNAL,\n            cv2.CHAIN_APPROX_SIMPLE); cnts = imutils.grab_contours(cnts)\n        c_guttae.append(len(cnts)) \n        rating.append('Yes' if c_guttae[n] > 0 else 'No')\n        type_p.append('Healthy' if rating[n] == 'No' else 'Disease')\n    cec_dict = {'Guttaes?':rating, 'Amount':c_guttae, 'Type Patch':type_p}\n    cec_df = pd.DataFrame(cec_dict,columns=['Amount','Guttaes?','Type Patch'])\n\n    return cec_df","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:35:17.958787Z","iopub.execute_input":"2022-06-16T03:35:17.959586Z","iopub.status.idle":"2022-06-16T03:35:17.967363Z","shell.execute_reply.started":"2022-06-16T03:35:17.959548Z","shell.execute_reply":"2022-06-16T03:35:17.966134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_cec = counter_guttaes(guttaes); print(data_cec)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:35:22.637617Z","iopub.execute_input":"2022-06-16T03:35:22.638457Z","iopub.status.idle":"2022-06-16T03:35:22.716104Z","shell.execute_reply.started":"2022-06-16T03:35:22.638419Z","shell.execute_reply":"2022-06-16T03:35:22.715303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Univariate Analysis","metadata":{}},{"cell_type":"code","source":"# analizar la distribuci√≥n de guttas a lo largo del dataset.\ndata_cec[{'Amount': ['min', 'max', 'median', 'skew']}].describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:40:10.404919Z","iopub.execute_input":"2022-06-16T03:40:10.405322Z","iopub.status.idle":"2022-06-16T03:40:10.424281Z","shell.execute_reply.started":"2022-06-16T03:40:10.40527Z","shell.execute_reply":"2022-06-16T03:40:10.423266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nprint('\\tDistribution: Healthy VS Diseased Cells\\n')\nsns.countplot(x = data_cec['Type Patch']); plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:43:09.820561Z","iopub.execute_input":"2022-06-16T03:43:09.82123Z","iopub.status.idle":"2022-06-16T03:43:09.99511Z","shell.execute_reply.started":"2022-06-16T03:43:09.821191Z","shell.execute_reply":"2022-06-16T03:43:09.994194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Building","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_images, tt_images, train_masks, tt_masks = train_test_split(images, labels, test_size = 0.2, random_state = 0)\ntest_images, val_images, test_masks, val_masks = train_test_split(tt_images, tt_masks, test_size = 0.4, random_state = 0)\nprint('Train Images :::', train_images.shape); print('Train Masks :::', train_masks.shape)\nprint('Test Images :::', test_images.shape); print('Test Masks :::', test_masks.shape)\nprint('Val Images :::', val_images.shape); print('Val Masks :::', val_masks.shape)\nprint(\"Classes CEC Patches ::: \", np.unique(train_masks))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:53:10.788379Z","iopub.execute_input":"2022-06-16T03:53:10.789083Z","iopub.status.idle":"2022-06-16T03:53:11.883136Z","shell.execute_reply.started":"2022-06-16T03:53:10.789042Z","shell.execute_reply":"2022-06-16T03:53:11.882155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import normalize\ntrain_images = normalize(train_images, axis = 1)\ntest_images = normalize(test_images, axis = 1)\nval_images = normalize(val_images, axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:53:20.590686Z","iopub.execute_input":"2022-06-16T03:53:20.591087Z","iopub.status.idle":"2022-06-16T03:53:20.885779Z","shell.execute_reply.started":"2022-06-16T03:53:20.591053Z","shell.execute_reply":"2022-06-16T03:53:20.884792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nclasses = 3; tr_cat = to_categorical(train_masks, num_classes = classes)\ntrain_cat = tr_cat.reshape((train_masks.shape[0], train_masks.shape[1],\n                            train_masks.shape[2], classes))\n\nts_cat = to_categorical(test_masks, num_classes = classes)\ntest_cat = ts_cat.reshape((test_masks.shape[0], test_masks.shape[1], \n                           test_masks.shape[2], classes))\n\nvl_cat = to_categorical(val_masks, num_classes = classes)\nval_cat = vl_cat.reshape((val_masks.shape[0], val_masks.shape[1], \n                           val_masks.shape[2], classes))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:54:05.579376Z","iopub.execute_input":"2022-06-16T03:54:05.579739Z","iopub.status.idle":"2022-06-16T03:54:06.265093Z","shell.execute_reply.started":"2022-06-16T03:54:05.579693Z","shell.execute_reply":"2022-06-16T03:54:06.264073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multi_unet_model(n_classes = 3, img_height = 96, img_width = 96, img_channels = 1, neurons = 32):\n    inputs = Input((img_height, img_width, img_channels)); s = inputs\n    # Contraction path\n    c1 = Conv2D(neurons, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(s)\n    c1 = Dropout(0.1)(c1)\n    c1 = Conv2D(neurons, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c1)\n    p1 = MaxPooling2D((2, 2))(c1)\n    \n    c2 = Conv2D(neurons * 2, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p1)\n    c2 = Dropout(0.1)(c2)\n    c2 = Conv2D(neurons * 2, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c2)\n    p2 = MaxPooling2D((2, 2))(c2)\n     \n    c3 = Conv2D(neurons * 4, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p2)\n    c3 = Dropout(0.2)(c3)\n    c3 = Conv2D(neurons * 4, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c3)\n    p3 = MaxPooling2D((2, 2))(c3)\n     \n    c4 = Conv2D(neurons * 8, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p3)\n    c4 = Dropout(0.2)(c4)\n    c4 = Conv2D(neurons * 8, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c4)\n    p4 = MaxPooling2D((2, 2))(c4)\n     \n    c5 = Conv2D(neurons * 16, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(p4)\n    c5 = Dropout(0.3)(c5)\n    c5 = Conv2D(neurons * 16, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c5)\n    \n    # Expansion path \n    u6 = Conv2DTranspose(128, (2, 2), strides = (2, 2), padding = 'same')(c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(neurons * 8, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u6)\n    c6 = Dropout(0.2)(c6)\n    c6 = Conv2D(neurons * 8, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c6)\n     \n    u7 = Conv2DTranspose(64, (2, 2), strides = (2, 2), padding = 'same')(c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(neurons * 4, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u7)\n    c7 = Dropout(0.2)(c7)\n    c7 = Conv2D(neurons * 4, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c7)\n     \n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding = 'same')(c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(neurons * 2, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u8)\n    c8 = Dropout(0.1)(c8)\n    c8 = Conv2D(neurons * 2, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c8)\n     \n    u9 = Conv2DTranspose(16, (2, 2), strides = (2, 2), padding = 'same')(c8)\n    u9 = concatenate([u9, c1], axis = 3)\n    c9 = Conv2D(neurons, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(u9)\n    c9 = Dropout(0.1)(c9)\n    c9 = Conv2D(neurons, (3, 3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(c9)\n     \n    outputs = Conv2D(n_classes, (1, 1), activation = 'softmax')(c9)\n     \n    model = Model(inputs = [inputs], outputs = [outputs])\n\n    model.summary()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-16T03:54:12.563484Z","iopub.execute_input":"2022-06-16T03:54:12.563829Z","iopub.status.idle":"2022-06-16T03:54:12.586276Z","shell.execute_reply.started":"2022-06-16T03:54:12.563798Z","shell.execute_reply":"2022-06-16T03:54:12.585505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_height = train_images.shape[1]\nimg_width  = train_images.shape[2]\nimg_channels = train_images.shape[3]\nmodel = multi_unet_model(n_classes = classes, img_height = img_height,\n        img_width = img_width, img_channels = img_channels, neurons = 32)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T05:21:21.921224Z","iopub.execute_input":"2022-06-16T05:21:21.922102Z","iopub.status.idle":"2022-06-16T05:21:22.138077Z","shell.execute_reply.started":"2022-06-16T05:21:21.922046Z","shell.execute_reply":"2022-06-16T05:21:22.137065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = 'adam'; lost = 'categorical_crossentropy'; metric = 'accuracy'\nmodel.compile(optimizer = opt, loss = [lost], metrics = [metric])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T05:21:25.17207Z","iopub.execute_input":"2022-06-16T05:21:25.172749Z","iopub.status.idle":"2022-06-16T05:21:25.189492Z","shell.execute_reply.started":"2022-06-16T05:21:25.172702Z","shell.execute_reply":"2022-06-16T05:21:25.188344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_predictions(img, gt, pred):\n    plt.figure(figsize = (16, 12)) # size fig.\n    plt.subplot(231); plt.title('CEC Image')\n    plt.imshow(img[:,:,0], cmap = 'gray')\n    plt.subplot(232); plt.title('CEC Mask')\n    plt.imshow(gt[:,:,0], cmap = 'inferno')\n    plt.subplot(233); plt.title('Prediction')\n    plt.imshow(pred, cmap = 'inferno'); plt.show()\n    \ndef display_results(img_ls, gt_ls, pred_ls):\n    fig, axs = plt.subplots(3, len(img_ls), figsize = (23,10))\n    for x in range(len(img_ls)):    \n        axs[0,x].imshow(img_ls[x][:,:,0], cmap = 'gray'); axs[0,x].axis('off')\n        axs[1,x].imshow(gt_ls[x][:,:,0], cmap = 'inferno');axs[1,x].axis('off')\n        axs[2,x].imshow(pred_ls[x], cmap = 'inferno'); axs[2,x].axis('off')\n    plt.show()\n    \ndef segment_patches(images = None, masks = None, samples = 1):\n    if samples != 1:\n        image_ls = []; mask_ls = []; predict_ls = []\n        randomize = random.sample(range(0,len(images)),samples)\n        for x in randomize:\n            image = images[x]; mask = masks[x]\n            image_norm = image[:,:,0][:,:,None]\n            image_in = np.expand_dims(image_norm,0)\n            pred_img = (model.predict(image_in))\n            predict = np.argmax(pred_img,axis=3)[0,:,:]\n            image_ls.append(image); mask_ls.append(mask)\n            predict_ls.append(predict) \n        display_results(image_ls, mask_ls, predict_ls)\n    else:\n        img_norm = test_images[0][:,:,0][:,:,None]\n        img_input = np.expand_dims(img_norm, 0)\n        predicted_mask = (model.predict(img_input))\n        predict_mask = np.argmax(predicted_mask,axis=3)[0,:,:]\n        show_predictions(test_images[0], test_masks[0], predict_mask)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:24:16.021626Z","iopub.execute_input":"2022-06-16T07:24:16.022399Z","iopub.status.idle":"2022-06-16T07:24:16.038155Z","shell.execute_reply.started":"2022-06-16T07:24:16.022357Z","shell.execute_reply":"2022-06-16T07:24:16.037352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import clear_output \nclass display_callback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs = None):\n        clear_output(wait = True); segment_patches()\n        print ('\\nPrediction after epoch {}\\n'.format(epoch+1))","metadata":{"execution":{"iopub.status.busy":"2022-06-16T05:21:28.491237Z","iopub.execute_input":"2022-06-16T05:21:28.491835Z","iopub.status.idle":"2022-06-16T05:21:28.497367Z","shell.execute_reply.started":"2022-06-16T05:21:28.491798Z","shell.execute_reply":"2022-06-16T05:21:28.496109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_images, train_cat, batch_size = 16, \n                    verbose =  1, epochs = 100, shuffle = False,\n                    validation_data = (test_images, test_cat),\n                    callbacks = [display_callback()])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T05:21:29.799283Z","iopub.execute_input":"2022-06-16T05:21:29.79982Z","iopub.status.idle":"2022-06-16T05:32:41.140719Z","shell.execute_reply.started":"2022-06-16T05:21:29.799779Z","shell.execute_reply":"2022-06-16T05:32:41.139787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot the training and validation accuracy and loss at each epoch\nfig = plt.figure(figsize = (20, 10))\nplt.subplot(1, 2, 1)\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\nplt.plot(epochs, loss, 'b', label = 'Training loss')\nplt.plot(epochs, val_loss, 'r', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs'); plt.ylabel('Loss'); plt.legend()\n\nplt.subplot(1, 2, 2)\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nplt.plot(epochs, acc, 'b', label = 'Training Accuracy')\nplt.plot(epochs, val_acc, 'r', label = 'Validation Accuracy')\nplt.title('Training and validation Accuracy')\nplt.xlabel('Epochs'); plt.ylabel('Accuracy')\nplt.legend(); plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T06:10:46.081844Z","iopub.execute_input":"2022-06-16T06:10:46.082511Z","iopub.status.idle":"2022-06-16T06:10:46.437052Z","shell.execute_reply.started":"2022-06-16T06:10:46.082477Z","shell.execute_reply":"2022-06-16T06:10:46.436108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('synth-trainer-100e.hdf5'); path = '../input/'\n# model.load_weights(path + 'synth-trainer-50e.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T06:13:37.201384Z","iopub.execute_input":"2022-06-16T06:13:37.202473Z","iopub.status.idle":"2022-06-16T06:13:37.46087Z","shell.execute_reply.started":"2022-06-16T06:13:37.202417Z","shell.execute_reply":"2022-06-16T06:13:37.459928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, acc_ts = model.evaluate(test_images, test_cat)\nprint(\"Accuracy Test is = \", (acc_ts * 100.0), \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-06-16T06:43:17.485028Z","iopub.execute_input":"2022-06-16T06:43:17.48553Z","iopub.status.idle":"2022-06-16T06:43:17.869679Z","shell.execute_reply.started":"2022-06-16T06:43:17.485492Z","shell.execute_reply":"2022-06-16T06:43:17.868947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, acc_vl = model.evaluate(val_images, val_cat)\nprint(\"Accuracy Val is = \", (acc_vl * 100.0), \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-06-16T06:43:21.212952Z","iopub.execute_input":"2022-06-16T06:43:21.213353Z","iopub.status.idle":"2022-06-16T06:43:21.490212Z","shell.execute_reply.started":"2022-06-16T06:43:21.213297Z","shell.execute_reply":"2022-06-16T06:43:21.48925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(test_images)\ny_pred_argmax = np.argmax(y_pred, axis = 3)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:52:46.049026Z","iopub.execute_input":"2022-06-16T07:52:46.049546Z","iopub.status.idle":"2022-06-16T07:52:46.443733Z","shell.execute_reply.started":"2022-06-16T07:52:46.04951Z","shell.execute_reply":"2022-06-16T07:52:46.44286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.metrics import MeanIoU\nIOU_keras = MeanIoU(num_classes = classes)  \nIOU_keras.update_state(test_masks[:,:,:,0], y_pred_argmax)\nprint(\"Mean IoU =\", IOU_keras.result().numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:52:47.496641Z","iopub.execute_input":"2022-06-16T07:52:47.496989Z","iopub.status.idle":"2022-06-16T07:52:47.546347Z","shell.execute_reply.started":"2022-06-16T07:52:47.496958Z","shell.execute_reply":"2022-06-16T07:52:47.544627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = np.array(IOU_keras.get_weights()).reshape(classes, classes) \ncontours_IoU = values[0,0] / (values[0,0] + values[0,1] + values[0,2] + values[1,0] + values[2,0])\ncells_IoU = values[1,1] / (values[1,1] + values[1,0] + values[1,2] + values[0,1] + values[2,1])\nguttaes_IoU = values[2,2] / (values[2,2] + values[2,0] + values[2,1] + values[0,2] + values[1,2])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:53:02.435114Z","iopub.execute_input":"2022-06-16T07:53:02.435489Z","iopub.status.idle":"2022-06-16T07:53:02.443668Z","shell.execute_reply.started":"2022-06-16T07:53:02.435456Z","shell.execute_reply":"2022-06-16T07:53:02.442777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Intersection over Union (IoU) for contours is ::: \", contours_IoU) \nprint(\"Intersection over Union (IoU) for cells is ::: \", cells_IoU) \nprint(\"Intersection over Union (IoU) for guttaes is ::: \", guttaes_IoU) ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:53:03.862317Z","iopub.execute_input":"2022-06-16T07:53:03.862733Z","iopub.status.idle":"2022-06-16T07:53:03.86824Z","shell.execute_reply.started":"2022-06-16T07:53:03.862698Z","shell.execute_reply":"2022-06-16T07:53:03.867055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment_patches(test_images, test_masks, 7)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:24:20.218993Z","iopub.execute_input":"2022-06-16T07:24:20.219411Z","iopub.status.idle":"2022-06-16T07:24:21.786788Z","shell.execute_reply.started":"2022-06-16T07:24:20.219376Z","shell.execute_reply":"2022-06-16T07:24:21.783707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment_patches(val_images, val_masks, 7)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:24:27.360559Z","iopub.execute_input":"2022-06-16T07:24:27.361021Z","iopub.status.idle":"2022-06-16T07:24:29.107946Z","shell.execute_reply.started":"2022-06-16T07:24:27.360984Z","shell.execute_reply":"2022-06-16T07:24:29.107094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test: Real CEC Patches (Only For Train With Images From GAN).","metadata":{}},{"cell_type":"code","source":"path_real = '../input/patches-bd/backup-real'\nr_images, r_fn_cor = read_cec_patches(path_real + '/images')\nr_cells, r_fn_cell = read_cec_patches(path_real + '/masks/cell')\nr_guttaes, r_fn_guttae = read_cec_patches(path_real + '/masks/guttae')\nr_images = np.array(r_images); r_images = np.expand_dims(r_images, axis = -1)\nr_cells = np.array(r_cells); r_cells = np.expand_dims(r_cells, axis = -1) \nr_guttaes = np.array(r_guttaes); r_guttaes = np.expand_dims(r_guttaes, axis = -1)\nr_backgrounds = r_cells + r_guttaes; r_backgrounds = 1 - r_backgrounds # contours.\nr_masks = np.concatenate((r_backgrounds, r_cells, r_guttaes), axis = -1)\nr_labels = encoder_pixels(r_masks) # encode pixels of the outgoing mask.\np_images = normalize(r_images, axis = 1); p_masks = r_labels ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:31:29.526725Z","iopub.execute_input":"2022-06-16T07:31:29.527721Z","iopub.status.idle":"2022-06-16T07:31:36.937027Z","shell.execute_reply.started":"2022-06-16T07:31:29.527674Z","shell.execute_reply":"2022-06-16T07:31:36.93598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_cat = to_categorical(p_masks, num_classes = classes)\np_cat = r_cat.reshape((p_masks.shape[0], p_masks.shape[1], \n                       p_masks.shape[2], classes))\n\n_, r_acc = model.evaluate(p_images, p_cat)\nprint(\"Accuracy is = \", (r_acc * 100.0), \"%\")","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:32:06.462664Z","iopub.execute_input":"2022-06-16T07:32:06.463476Z","iopub.status.idle":"2022-06-16T07:32:06.972906Z","shell.execute_reply.started":"2022-06-16T07:32:06.463439Z","shell.execute_reply":"2022-06-16T07:32:06.971881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_y_pred = model.predict(p_images)\nr_y_pred_argmax = np.argmax(r_y_pred, axis = 3)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:32:44.220689Z","iopub.execute_input":"2022-06-16T07:32:44.221551Z","iopub.status.idle":"2022-06-16T07:32:44.600424Z","shell.execute_reply.started":"2022-06-16T07:32:44.221513Z","shell.execute_reply":"2022-06-16T07:32:44.599524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.metrics import MeanIoU\nr_IOU_keras = MeanIoU(num_classes = classes)  \nr_IOU_keras.update_state(p_masks[:,:,:,0], r_y_pred_argmax)\nprint(\"Mean IoU =\", r_IOU_keras.result().numpy())","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:32:47.050459Z","iopub.execute_input":"2022-06-16T07:32:47.051097Z","iopub.status.idle":"2022-06-16T07:32:47.125034Z","shell.execute_reply.started":"2022-06-16T07:32:47.051046Z","shell.execute_reply":"2022-06-16T07:32:47.124108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_values = np.array(r_IOU_keras.get_weights()).reshape(classes, classes) \nr_contours_IoU = r_values[0,0] / (r_values[0,0] + r_values[0,1] + r_values[0,2] + r_values[1,0] + r_values[2,0])\nr_cells_IoU = r_values[1,1] / (r_values[1,1] + r_values[1,0] + r_values[1,2] + r_values[0,1] + r_values[2,1])\nr_guttaes_IoU = values[2,2] / (r_values[2,2] + r_values[2,0] + r_values[2,1] + r_values[0,2] + r_values[1,2])","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:33:13.72767Z","iopub.execute_input":"2022-06-16T07:33:13.728035Z","iopub.status.idle":"2022-06-16T07:33:13.736326Z","shell.execute_reply.started":"2022-06-16T07:33:13.728005Z","shell.execute_reply":"2022-06-16T07:33:13.735361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Intersection over Union (IoU) for contours is ::: \", r_contours_IoU) \nprint(\"Intersection over Union (IoU) for cells is ::: \", r_cells_IoU) \nprint(\"Intersection over Union (IoU) for guttaes is ::: \", r_guttaes_IoU) ","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:33:18.231694Z","iopub.execute_input":"2022-06-16T07:33:18.232548Z","iopub.status.idle":"2022-06-16T07:33:18.237559Z","shell.execute_reply.started":"2022-06-16T07:33:18.232508Z","shell.execute_reply":"2022-06-16T07:33:18.23637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"segment_patches(p_images, p_masks, 7)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:34:27.600605Z","iopub.execute_input":"2022-06-16T07:34:27.601428Z","iopub.status.idle":"2022-06-16T07:34:28.838216Z","shell.execute_reply.started":"2022-06-16T07:34:27.601392Z","shell.execute_reply":"2022-06-16T07:34:28.837456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict on Large Image (CEC Image Not Seen)","metadata":{}},{"cell_type":"code","source":"!pip install patchify","metadata":{"execution":{"iopub.status.busy":"2022-06-16T07:54:49.58887Z","iopub.execute_input":"2022-06-16T07:54:49.589916Z","iopub.status.idle":"2022-06-16T07:54:59.905309Z","shell.execute_reply.started":"2022-06-16T07:54:49.589864Z","shell.execute_reply":"2022-06-16T07:54:59.904213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from patchify import patchify, unpatchify\nlarge_image = cv2.imread('../input/cec-images/01_20190108_132928_rc_a_POSSO JORGE.png', 0)\nlarge_image = large_image[32:416, 16:208] # cut section of cec image for trainer.\npatches = patchify(large_image, (96, 96), step = 96)  #Step=256 for 256 patches means no overlap\n\npredicted_patches = []\nfor i in range(patches.shape[0]):\n    for j in range(patches.shape[1]):\n        single_patch = patches[i,j,:,:]       \n        single_patch_norm = np.expand_dims(normalize(np.array(single_patch), axis=1),2)\n        single_patch_input=np.expand_dims(single_patch_norm, 0)\n        single_patch_prediction = (model.predict(single_patch_input))\n        single_patch_predicted_img=np.argmax(single_patch_prediction, axis=3)[0,:,:]\n        predicted_patches.append(single_patch_predicted_img)\n\npredicted_patches = np.array(predicted_patches)\npredicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], 96, 96) )\nreconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\nplt.hist(reconstructed_image.flatten()) \n\nplt.figure(figsize = (8, 8))\nplt.subplot(221)\nplt.title('Large Image')\nplt.imshow(large_image, cmap = 'gray')\nplt.subplot(222)\nplt.title('Prediction of large Image')\nplt.imshow(reconstructed_image, cmap = 'inferno')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}